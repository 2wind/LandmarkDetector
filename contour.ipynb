{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python388jvsc74a57bd0781a2a4cf53b5641473fad8676e8c0a38872e1ed5a7fb83d02846a3135ad21c8",
   "display_name": "Python 3.8.8 64-bit ('outline': conda)"
  },
  "metadata": {
   "interpreter": {
    "hash": "781a2a4cf53b5641473fad8676e8c0a38872e1ed5a7fb83d02846a3135ad21c8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# knnMatch 함수로부터 올바른 매칭점 찾기 (match_good_knn.py)\n",
    "\n",
    "import cv2, numpy as np\n",
    "import imutils\n",
    "import pandas as pd\n",
    "\n",
    "photo_img_path = \"AutoAlign_test/B17545___________000_lat_photo.jpg\"\n",
    "film_img_path = \"AutoAlign_test/B17545___________000_lat_film.jpg\"\n",
    "film_tsv_path = \"AutoAlign_test/B17545___________000_lat_film.txt\"\n",
    "\n",
    "landmark_regex_string = '29@[2479]|30@[34]'\n",
    "landmark_number = 6\n",
    "\n",
    "photo = cv2.imread(photo_img_path)\n",
    "film = cv2.imread(film_img_path, cv2.IMREAD_GRAYSCALE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_image(image, size=(800, 600)):\n",
    "    cv2.namedWindow('border', cv2.WINDOW_NORMAL)\n",
    "    cv2.resizeWindow('border', size[0], size[1])\n",
    "\n",
    "    cv2.imshow('border', image)\n",
    "    cv2.waitKey()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_tsv(tsv_path: str):\n",
    "    '''\n",
    "    parse_tsv(tsv_path: str):\n",
    "        tsv_path: str: full path to text file, in tab separated values format.\n",
    "\n",
    "    Opens text file in tsv_path as tsv. loads it as pandas dataframe, in a following format:\n",
    "\n",
    "    |   name    |   X   |   Y   |\n",
    "    =============================\n",
    "    |   ...     |  ...  |  ...  |\n",
    "    |  '29@2'   | 324.7 | 250.4 |\n",
    "    |   (str)   | float | float |\n",
    "    |   ...     |  ...  |  ...  |\n",
    "\n",
    "    If fails, prints error message and quits.\n",
    "\n",
    "    return:\n",
    "        df: Pandas.dataframe() that contains landmark information.\n",
    "    '''\n",
    "    # Loading dataframe\n",
    "\n",
    "    df = pd.read_csv(tsv_path,  sep='\\t')\n",
    "    df = df.iloc[:99, 0:3]\n",
    "    \n",
    "    df.columns = ['name', 'X', 'Y']\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def extract_landmarks(df, landmark_regex, landmark_length):\n",
    "    '''\n",
    "    extract_landmarks(df: pandas.dataframe(), landmark_regex: str, landmark_length: int):\n",
    "        df: Pandas.dataframe() that contains landmark information.\n",
    "        landmark_regex: Regular Expression String that matches certain landmark names.\n",
    "        landmark_length: length of landmarks(how many landmarks do we want to extract?).\n",
    "\n",
    "    Gathers needed landmarks, sort, drop name, and change it into numpy array.\n",
    "\n",
    "    returns:\n",
    "        landmark: numpy.array(): (landmark_length, 2) shaped numpy array with landmark(x, y) in each row.\n",
    "    '''\n",
    "    # (gathering only needed landmarks)\n",
    "    df = df.loc[df['name'].str.contains(landmark_regex, regex=True), :]\n",
    "    # there are **18** landmarks that is unique and valid among all files\n",
    "    df = df.sort_values(by=['name'])\n",
    "    df = df.loc[:, ['X', 'Y']]\n",
    "    df = df.reset_index(drop=True)\n",
    "\n",
    "    # ... and landmark\n",
    "    landmark = df.to_numpy(dtype=np.float32)\n",
    "    return landmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "border = imutils.auto_canny(photo)\n",
    "\n",
    "# show_image(border)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "array([[1648.,  872.],\n       [1846., 1255.],\n       [1737., 1388.],\n       [1782., 1555.],\n       [1729., 1649.],\n       [1610., 1738.]], dtype=float32)"
     },
     "metadata": {}
    }
   ],
   "source": [
    "film_landmarks = extract_landmarks(parse_tsv(film_tsv_path), landmark_regex_string, landmark_number)\n",
    "display(film_landmarks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[1578  840]\n [1878 1770]]\n"
     ]
    }
   ],
   "source": [
    "film2 = imutils.adjust_brightness_contrast(film, 0., 50)\n",
    "margin = 32\n",
    "box = np.array([[min(film_landmarks[:, 0])-margin, min(film_landmarks[:, 1])-margin], [max(film_landmarks[:, 0])+margin, max(film_landmarks[:, 1])+margin]], dtype=int)\n",
    "print(box)\n",
    "\n",
    "crop = film2[box[0,1]:box[1,1],box[1,0]-500:box[1,0]]\n",
    "(thresh, im_bw) = cv2.threshold(crop, 20, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "\n",
    "canny2 = imutils.auto_canny(im_bw)\n",
    "show_image(canny2)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_fft(img):\n",
    "    f = np.fft.fft2(img)\n",
    "    fshift = np.fft.fftshift(f)\n",
    "    return fshift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_y, max_x = max(zip(*np.nonzero(border)), key=lambda c: c[1])\n",
    "border2 = border[max_y-300:max_y+300, max_x-300:max_x+margin]\n",
    "show_image(border2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(600, 332)\n(930, 500)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import imreg_dft\n",
    "print(border2.shape)\n",
    "print(canny2.shape)\n",
    "comp1 = cv2.resize(border2, (600,300))\n",
    "comp2 = cv2.resize(canny2, (600,300))\n",
    "show_image(comp1)\n",
    "show_image(comp2)\n",
    "result  = imreg_dft.imreg.similarity(comp1, comp2)\n",
    "show_image(result[\"timg\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "matches:25/350\n"
     ]
    }
   ],
   "source": [
    "# ORB로 서술자 추출 ---①\n",
    "detector = cv2.ORB_create()\n",
    "kp1, desc1 = detector.detectAndCompute(border2, None)\n",
    "kp2, desc2 = detector.detectAndCompute(canny2, None)\n",
    "# BF-Hamming 생성 ---②\n",
    "matcher = cv2.BFMatcher(cv2.NORM_HAMMING2)\n",
    "# knnMatch, k=2 ---③\n",
    "matches = matcher.knnMatch(desc1, desc2, 2)\n",
    "\n",
    "# 첫번재 이웃의 거리가 두 번째 이웃 거리의 75% 이내인 것만 추출---⑤\n",
    "ratio = 0.75\n",
    "good_matches = [first for first,second in matches \\\n",
    "                    if first.distance < second.distance * ratio]\n",
    "print('matches:%d/%d' %(len(good_matches),len(matches)))\n",
    "\n",
    "# 좋은 매칭만 그리기\n",
    "res = cv2.drawMatches(border2, kp1, canny2, kp2, good_matches, None, \\\n",
    "                    flags=cv2.DRAW_MATCHES_FLAGS_NOT_DRAW_SINGLE_POINTS)\n",
    "# 결과 출력                    \n",
    "show_image(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[-8.43880405e-01 -5.84283184e-03  1.89575319e+02]\n [-2.35078103e+00  3.54154505e-04  5.24101552e+02]\n [-4.47602480e-03 -1.74727845e-05  1.00000000e+00]]\n(600, 332)\n[[[  0.   0.]]\n\n [[  0. 599.]]\n\n [[331. 599.]]\n\n [[331.   0.]]]\n(930, 300)\n[array([[[189, 524]],\n\n       [[188, 529]],\n\n       [[189, 515]],\n\n       [[186, 527]]])]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 좋은 매칭점의 queryIdx로 원본 영상의 좌표 구하기 ---③\n",
    "src_pts = np.float32([ kp1[m.queryIdx].pt for m in good_matches ])\n",
    "# 좋은 매칭점의 trainIdx로 대상 영상의 좌표 구하기 ---④\n",
    "dst_pts = np.float32([ kp2[m.trainIdx].pt for m in good_matches ])\n",
    "mtrx, mask = cv2.findHomography(src_pts, dst_pts)\n",
    "print(mtrx)\n",
    "h,w, = border2.shape[:2]\n",
    "pts = np.float32([ [[0,0]],[[0,h-1]],[[w-1,h-1]],[[w-1,0]] ])\n",
    "# 원본 영상 좌표를 원근 변환  ---⑦\n",
    "print(border2.shape)\n",
    "print(pts)\n",
    "dst = cv2.perspectiveTransform(pts,mtrx)\n",
    "print(canny2.shape)\n",
    "print([np.int32(dst)])\n",
    "\n",
    "# 변환 좌표 영역을 대상 영상에 그리기 ---⑧\n",
    "canny2 = cv2.polylines(canny2,np.int32(dst),True,255,3, cv2.LINE_AA)\n",
    "\n",
    "\n",
    "show_image(canny2)\n",
    "\n",
    "# 좋은 매칭 그려서 출력 ---⑨\n",
    "res = cv2.drawMatches(border2, kp1, canny2, kp2, good_matches, None, \\\n",
    "                    flags=cv2.DRAW_MATCHES_FLAGS_NOT_DRAW_SINGLE_POINTS)\n",
    "cv2.imshow('Matching Homography', res)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}